{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Sandwich model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the forked model [forked model](https://www.kaggle.com/nicksexton/different-embeddings-with-attention-fork-fork) we've inherited some code for creating an attention mechanism that just sits nicely on top of the two LSTMs that make up the recurrent part of the model. \n",
    "\n",
    "In this notebook, I'm going to implement an attention algorithm that sits *between* the two LSTMs (or more, if we decide to continue stacking.) This has the advantage that for each point in its sequence, the second LSTM (which we'll call LSTM_q) is able to look at a much wider input (context) than just it's own hidden state and the current output of the previous LSTM (which we'll call LSTM_p), and means that the two LSTMs aren't necessarily aligned (i.e., they don't need to have the same number of timesteps).\n",
    "\n",
    "LSTM_p will be bidirectional, and will have the same number of timesteps (Tp) as the maximum sequence length. This feeds into an attention mechanism that computes a context vector, which is fed into LSTM_q, that has a variable sequence length (Tq). \n",
    "\n",
    "This frees up LSTM_q such that across Tq timesteps, it's free to learn its own articulated representation of what a question is. (For example, if Tq=3, it might correspond to representations for the beginning, middle, and end of the question). But an important point is the model will develop its own representations of quora questions, rather than following any of my own preconceived ideas.\n",
    "\n",
    "Finally, the sequential output of LSTM_q across Tq timesteps is concatenated and fed into a fully connected layer, and finally into a classifier.\n",
    "\n",
    "The model is quite slow to train (~200s per epoch on my GPU) but I think produces promising enough results from a single set of embeddings to be worth experimenting with.\n",
    "\n",
    "The code for the attention model is adapted from Andrew Ng's Deep Learning Coursera course, with some adaptations to make it applicable to a sequence-to-binary-classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D, Concatenate, Flatten, RepeatVector, Dot, LSTM\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1306122, 3)\n",
      "Test shape :  (56370, 2)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")\n",
    "print(\"Train shape : \",train_df.shape)\n",
    "print(\"Test shape : \",test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ad1e9fdf97f3291a7d1797b25f0c7a0c5d1f1edd"
   },
   "source": [
    "Next steps are as follows:\n",
    " * Split the training dataset into train and val sample. Cross validation is a time consuming process and so let us do simple train val split.\n",
    " * Fill up the missing values in the text column with '_na_'\n",
    " * Tokenize the text column and convert them to vector sequences\n",
    " * Pad the sequence as needed - if the number of words in the text is greater than 'max_len' trunacate them to 'max_len' or if the number of words in the text is lesser than 'max_len' add zeros for remaining values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "ba5a1b8109dee2c9fbc628d5da4a7c3447d42fb8"
   },
   "outputs": [],
   "source": [
    "## split to train and val\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.08, random_state=2018)\n",
    "\n",
    "## some config values \n",
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 95000 # 95000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 70 # max number of words in a question to use\n",
    "\n",
    "\n",
    "## fill up the missing values\n",
    "train_X = train_df[\"question_text\"].fillna(\"_##_\").values\n",
    "val_X = val_df[\"question_text\"].fillna(\"_##_\").values\n",
    "test_X = test_df[\"question_text\"].fillna(\"_##_\").values\n",
    "\n",
    "## Tokenize the sentences\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(train_X))\n",
    "train_X = tokenizer.texts_to_sequences(train_X)\n",
    "val_X = tokenizer.texts_to_sequences(val_X)\n",
    "test_X = tokenizer.texts_to_sequences(test_X)\n",
    "\n",
    "## Pad the sentences \n",
    "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
    "val_X = pad_sequences(val_X, maxlen=maxlen)\n",
    "test_X = pad_sequences(test_X, maxlen=maxlen)\n",
    "\n",
    "## Get the target values\n",
    "train_y = train_df['target'].values\n",
    "val_y = val_df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "1d71ba60f46fe09a0807342e02b69cde8db930ff"
   },
   "outputs": [],
   "source": [
    "#shuffling the data\n",
    "#np.random.seed(2018)\n",
    "#trn_idx = np.random.permutation(len(train_X))\n",
    "#val_idx = np.random.permutation(len(val_X))\n",
    "\n",
    "#train_X = train_X[trn_idx]\n",
    "#val_X = val_X[val_idx]\n",
    "#train_y = train_y[trn_idx]\n",
    "#val_y = val_y[val_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for the Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom softmax activation function\n",
    "def softmax(x, axis=1):\n",
    "    \"\"\"Softmax activation function.\n",
    "    # Arguments\n",
    "        x : Tensor.\n",
    "        axis: Integer, axis along which the softmax normalization is applied.\n",
    "    # Returns\n",
    "        Tensor, output of softmax transformation.\n",
    "    # Raises\n",
    "        ValueError: In case `dim(x) == 1`.\n",
    "    \"\"\"\n",
    "    ndim = K.ndim(x)\n",
    "    if ndim == 2:\n",
    "        return K.softmax(x)\n",
    "    elif ndim > 2:\n",
    "        e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
    "        s = K.sum(e, axis=axis, keepdims=True)\n",
    "        return e / s\n",
    "    else:\n",
    "        raise ValueError('Cannot apply softmax to a tensor that is 1D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one_step_attention\n",
    "\n",
    "def one_step_attention(h, s_prev):\n",
    "    \"\"\"\n",
    "    Performs one step of attention: Outputs a context vector computed as a dot product of the attention weights\n",
    "    \"alphas\" and the hidden states \"a\" of the Bi-LSTM.\n",
    "    \n",
    "    Arguments:\n",
    "    h -- hidden state output of the Bi-LSTM, numpy-array of shape (m, Tp, 2*n_a)\n",
    "    s_prev -- previous hidden state of the (post-attention) LSTM, numpy-array of shape (m, n_s)\n",
    "    \n",
    "    Returns:\n",
    "    context -- context vector, input of the next (post-attetion) LSTM cell\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use repeator to repeat s_prev to be of shape (m, Tp, n_s) so that you can concatenate it with all hidden states \"a\" (≈ 1 line)\n",
    "    s_prev = repeator(s_prev)\n",
    "    # Use concatenator to concatenate h and s_prev on the last axis (≈ 1 line)\n",
    "    concat = concatenator([h, s_prev])\n",
    "    # Use densor1 to propagate concat through a small fully-connected neural network to compute the \"intermediate energies\" variable e. (≈1 lines)\n",
    "    e = densor1(concat)\n",
    "    # Use densor2 to propagate e through a small fully-connected neural network to compute the \"energies\" variable energies. (≈1 lines)\n",
    "    energies = densor2(e)\n",
    "    # Use \"activator\" on \"energies\" to compute the attention weights \"alphas\" (≈ 1 line)\n",
    "    alphas = activator(energies)\n",
    "    # Use dotor together with \"alphas\" and \"h\" to compute the context vector to be given to the next (post-attention) LSTM-cell (≈ 1 line)\n",
    "    context = dotor([alphas, h])\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the sequence length for LSTMs 1 (Tp) and 2 (Tq)\n",
    "Tp = maxlen\n",
    "Tq = 6\n",
    "n_p = 256 # hidden state size of LSTM 1\n",
    "n_q = 128 # 128 # hidden state size of LSTM 2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined shared layers as global variables\n",
    "repeator = RepeatVector(Tp)\n",
    "concatenator = Concatenate(axis=-1)\n",
    "densor1 = Dense(30, activation = \"tanh\") # was 10\n",
    "densor2 = Dense(1, activation = \"relu\")\n",
    "activator = Activation(softmax, name='attention_weights') # We are using a custom softmax(axis = 1) loaded in this notebook\n",
    "dotor = Dot(axes = 1)\n",
    "post_activation_LSTM_cell = CuDNNLSTM(n_q, return_state = True, name='LSTM_q')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use these layers $T_q$ times in a `for` loop to generate an output. The algorithm consists of the following steps.\n",
    "\n",
    "1. Propagate the input into a [Bidirectional](https://keras.io/layers/wrappers/#bidirectional) [LSTM](https://keras.io/layers/recurrent/#lstm)\n",
    "2. Iterate for $t = 0, \\dots, T_q-1$: \n",
    "    1. Call `one_step_attention()` on $[\\alpha^{<t,1>},\\alpha^{<t,2>}, ..., \\alpha^{<t,T_p>}]$ and $s^{<t-1>}$ to get the context vector $context^{<t>}$.\n",
    "    2. Give $context^{<t>}$ to the post-attention LSTM cell, also passing in the previous hidden-state $s^{\\langle t-1\\rangle}$ and cell-states $c^{\\langle t-1\\rangle}$ of this LSTM using `initial_state= [previous hidden state, previous cell state]`. Get back the new hidden state $s^{<t>}$ and the new cell state $c^{<t>}$.\n",
    "    3. add the cell state $c^{<t>}$ and hidden state $s^{<t>}$ to a list of states\n",
    "3. Concatenate the list of states, pass this into a fully connected layer, and then into a sigmoid binary classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_attention_sandwich_model(Tp, Tq, n_p, n_q, embed_size, max_features, embed_matrix):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    Tp -- length of the first LSTM's sequence (ie. max sequence length)\n",
    "    Tq -- length of the second LSTM's sequence\n",
    "    n_p -- hidden state size of the Bi-LSTM\n",
    "    n_q -- hidden state size of the post-attention LSTM\n",
    "    embed_size -- number of embedding dimensions\n",
    "    max_features -- number of embedded features (i.e. tokenized word count)\n",
    "    embed_matrix -- embedding matrix\n",
    "    machine_vocab_size -- size of the python dictionary \"machine_vocab\" # = 1 for classifier\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the inputs of your model with a shape (Tx,)\n",
    "    # Define s0 and c0, initial hidden state for LSTM_q of shape (n_q,)\n",
    "    print (\"Tp:\", Tp)\n",
    "    print (\"embed size\", embed_size)\n",
    "    print (\"max features\", max_features)\n",
    "    X = Input(shape=(Tp,), name='input') \n",
    "    s0 = Input(shape=(n_q,), name='s0')\n",
    "    c0 = Input(shape=(n_q,), name='c0')\n",
    "    s = s0\n",
    "    c = c0\n",
    "    \n",
    "    E = Embedding(max_features, embed_size, weights=[embed_matrix], trainable=False)(X)\n",
    "    \n",
    "    # Initialize empty list of hidden cell state vectors\n",
    "    states = []\n",
    "    \n",
    "    # Define the pre-attention Bi-LSTM. \n",
    "    a = Bidirectional(CuDNNLSTM(n_p, return_sequences=True, input_shape=(Tp, embed_size), name='LSTM_p1'))(E)\n",
    "    # 2: Iterate for Tq steps\n",
    "    for t in range(Tq):\n",
    "    \n",
    "        # 2.A: Perform one step of the attention mechanism to get back the context vector at step t\n",
    "        context = one_step_attention(a, s)\n",
    "        \n",
    "        # 2.B: Apply the post-attention LSTM_q cell to the \"context\" vector.\n",
    "        s, _, c = post_activation_LSTM_cell(inputs=context, initial_state=[s, c])\n",
    "        \n",
    "        # 2.C: Append states to the \"states\" list (≈ 1 line)\n",
    "        states.append(c)\n",
    "        states.append(s)\n",
    "    \n",
    "    # 3: Flatten the output of LSTM_q\n",
    "    f = Concatenate()(states)\n",
    "    x = Dense(64, activation=\"relu\")(f)\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    # Create model instance taking three inputs and returning the list of outputs. (≈ 1 line)\n",
    "    model = Model(inputs=[X, s0, c0], outputs=x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "_uuid": "b9d263852f653e466e24f9827548d7d1a7ee7262"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove.840B.300d\t\t\tparagram_300_sl999\r\n",
      "GoogleNews-vectors-negative300\twiki-news-300d-1M\r\n"
     ]
    }
   ],
   "source": [
    "# a look at the available embeddings\n",
    "!ls ../input/embeddings/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7c0010e518288bc7f588776c58610949140a139a"
   },
   "source": [
    "**Glove Embeddings:**\n",
    "\n",
    "For now, let's use the GloVe embeddings for the attention sandwich model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "_uuid": "23f130e80159bb1701e449e2e91199dbfff1f1d4"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
    "\n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tp: 70\n",
      "embed size 300\n",
      "max features 95000\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 70)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 70, 300)      28500000    input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "s0 (InputLayer)                 (None, 96)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 70, 512)      1142784     embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_2 (RepeatVector)  (None, 70, 96)       0           s0[0][0]                         \n",
      "                                                                 LSTM_q[0][0]                     \n",
      "                                                                 LSTM_q[1][0]                     \n",
      "                                                                 LSTM_q[2][0]                     \n",
      "                                                                 LSTM_q[3][0]                     \n",
      "                                                                 LSTM_q[4][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 70, 608)      0           bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_2[0][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_2[1][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_2[2][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_2[3][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_2[4][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_2[5][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 70, 30)       18270       concatenate_3[0][0]              \n",
      "                                                                 concatenate_3[1][0]              \n",
      "                                                                 concatenate_3[2][0]              \n",
      "                                                                 concatenate_3[3][0]              \n",
      "                                                                 concatenate_3[4][0]              \n",
      "                                                                 concatenate_3[5][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 70, 1)        31          dense_5[0][0]                    \n",
      "                                                                 dense_5[1][0]                    \n",
      "                                                                 dense_5[2][0]                    \n",
      "                                                                 dense_5[3][0]                    \n",
      "                                                                 dense_5[4][0]                    \n",
      "                                                                 dense_5[5][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (Activation)  (None, 70, 1)        0           dense_6[0][0]                    \n",
      "                                                                 dense_6[1][0]                    \n",
      "                                                                 dense_6[2][0]                    \n",
      "                                                                 dense_6[3][0]                    \n",
      "                                                                 dense_6[4][0]                    \n",
      "                                                                 dense_6[5][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 1, 512)       0           attention_weights[0][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[1][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[2][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[3][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[4][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[5][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 (None, 96)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "LSTM_q (CuDNNLSTM)              [(None, 96), (None,  234240      dot_2[0][0]                      \n",
      "                                                                 s0[0][0]                         \n",
      "                                                                 c0[0][0]                         \n",
      "                                                                 dot_2[1][0]                      \n",
      "                                                                 LSTM_q[0][0]                     \n",
      "                                                                 LSTM_q[0][2]                     \n",
      "                                                                 dot_2[2][0]                      \n",
      "                                                                 LSTM_q[1][0]                     \n",
      "                                                                 LSTM_q[1][2]                     \n",
      "                                                                 dot_2[3][0]                      \n",
      "                                                                 LSTM_q[2][0]                     \n",
      "                                                                 LSTM_q[2][2]                     \n",
      "                                                                 dot_2[4][0]                      \n",
      "                                                                 LSTM_q[3][0]                     \n",
      "                                                                 LSTM_q[3][2]                     \n",
      "                                                                 dot_2[5][0]                      \n",
      "                                                                 LSTM_q[4][0]                     \n",
      "                                                                 LSTM_q[4][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1152)         0           LSTM_q[0][2]                     \n",
      "                                                                 LSTM_q[0][0]                     \n",
      "                                                                 LSTM_q[1][2]                     \n",
      "                                                                 LSTM_q[1][0]                     \n",
      "                                                                 LSTM_q[2][2]                     \n",
      "                                                                 LSTM_q[2][0]                     \n",
      "                                                                 LSTM_q[3][2]                     \n",
      "                                                                 LSTM_q[3][0]                     \n",
      "                                                                 LSTM_q[4][2]                     \n",
      "                                                                 LSTM_q[4][0]                     \n",
      "                                                                 LSTM_q[5][2]                     \n",
      "                                                                 LSTM_q[5][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 64)           73792       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            65          dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 29,969,182\n",
      "Trainable params: 1,469,182\n",
      "Non-trainable params: 28,500,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_attention_sandwich_model(Tp, Tq, n_p, n_q, embed_size, max_features, embedding_matrix)\n",
    "opt = RMSprop(lr=1e-3)\n",
    "model.compile(opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And code to evaluate the model (F1 scores at various thresholds) on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def calc_f1_scores(model, dev_x, dev_y):\n",
    "    \n",
    "    s0_val = np.zeros((dev_x.shape[0], n_q))\n",
    "    c0_val = np.zeros((dev_x.shape[0], n_q))\n",
    "\n",
    "    pred_glove_dev_Y = model.predict([dev_x, s0_val, c0_val], batch_size=1024, verbose=1)\n",
    "\n",
    "    best_thresh = -1 # init value\n",
    "    best_f1 = 0\n",
    "\n",
    "    for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "\n",
    "        thresh = np.round(thresh, 2)\n",
    "    \n",
    "        f1 = metrics.f1_score(dev_y, (pred_glove_dev_Y>thresh).astype(int))\n",
    "        print(\"F1 score at threshold {0} is {1}\".format(thresh, f1))\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_thresh = thresh\n",
    "\n",
    "        \n",
    "    print(\"Best F1 score was at threshold {0}, {1}\".format(best_thresh, best_f1))\n",
    "    return (best_thresh, best_f1, pred_glove_dev_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the context vectors for LSTM_q's hidden state\n",
    "s0 = np.zeros((train_X.shape[0], n_q))\n",
    "c0 = np.zeros((train_X.shape[0], n_q))\n",
    "\n",
    "s0_val = np.zeros((val_X.shape[0], n_q))\n",
    "c0_val = np.zeros((val_X.shape[0], n_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "_uuid": "a560ab0dbab9cf6fdbdae6721ec030e300f19d78",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1201632 samples, validate on 104490 samples\n",
      "Epoch 1/3\n",
      "1201632/1201632 [==============================] - 225s 187us/step - loss: 0.1192 - acc: 0.9538 - val_loss: 0.1035 - val_acc: 0.9589\n",
      "Epoch 2/3\n",
      "1201632/1201632 [==============================] - 225s 188us/step - loss: 0.1009 - acc: 0.9600 - val_loss: 0.1010 - val_acc: 0.9595\n",
      "Epoch 3/3\n",
      "1201632/1201632 [==============================] - 226s 188us/step - loss: 0.0930 - acc: 0.9627 - val_loss: 0.0991 - val_acc: 0.9609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ffa73af8c18>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([train_X, s0, c0], train_y, batch_size=512, epochs=3, \n",
    "#          class_weight = {0: 1., 1: 2.},\n",
    "          validation_data=([val_X, s0_val, c0_val], val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Sandwich model\n",
      "104490/104490 [==============================] - 7s 66us/step\n",
      "F1 score at threshold 0.1 is 0.6311949261940843\n",
      "F1 score at threshold 0.11 is 0.6381563861499656\n",
      "F1 score at threshold 0.12 is 0.6428571428571429\n",
      "F1 score at threshold 0.13 is 0.6482096276974152\n",
      "F1 score at threshold 0.14 is 0.6536168162380294\n",
      "F1 score at threshold 0.15 is 0.6580589891078203\n",
      "F1 score at threshold 0.16 is 0.6630650769995031\n",
      "F1 score at threshold 0.17 is 0.6662060301507537\n",
      "F1 score at threshold 0.18 is 0.668826631090782\n",
      "F1 score at threshold 0.19 is 0.6712566758895824\n",
      "F1 score at threshold 0.2 is 0.6746532977407382\n",
      "F1 score at threshold 0.21 is 0.6760507794514241\n",
      "F1 score at threshold 0.22 is 0.67787598856915\n",
      "F1 score at threshold 0.23 is 0.6795620928202029\n",
      "F1 score at threshold 0.24 is 0.6801762114537445\n",
      "F1 score at threshold 0.25 is 0.6814855345051638\n",
      "F1 score at threshold 0.26 is 0.6813004762890867\n",
      "F1 score at threshold 0.27 is 0.6840122767857143\n",
      "F1 score at threshold 0.28 is 0.6842327744117233\n",
      "F1 score at threshold 0.29 is 0.6832006822057988\n",
      "F1 score at threshold 0.3 is 0.6822905468358058\n",
      "F1 score at threshold 0.31 is 0.6810294968189705\n",
      "F1 score at threshold 0.32 is 0.6813138686131387\n",
      "F1 score at threshold 0.33 is 0.6802711065271844\n",
      "F1 score at threshold 0.34 is 0.6797473058342622\n",
      "F1 score at threshold 0.35 is 0.680161943319838\n",
      "F1 score at threshold 0.36 is 0.6779635373326273\n",
      "F1 score at threshold 0.37 is 0.6770428015564203\n",
      "F1 score at threshold 0.38 is 0.6767055931161646\n",
      "F1 score at threshold 0.39 is 0.676825495049505\n",
      "F1 score at threshold 0.4 is 0.6758126120508224\n",
      "F1 score at threshold 0.41 is 0.6752492346338018\n",
      "F1 score at threshold 0.42 is 0.674040132722389\n",
      "F1 score at threshold 0.43 is 0.6737848605577689\n",
      "F1 score at threshold 0.44 is 0.6711096836357796\n",
      "F1 score at threshold 0.45 is 0.6686620287979291\n",
      "F1 score at threshold 0.46 is 0.6666666666666667\n",
      "F1 score at threshold 0.47 is 0.6640939321783398\n",
      "F1 score at threshold 0.48 is 0.6625868342705921\n",
      "F1 score at threshold 0.49 is 0.6592654424040068\n",
      "F1 score at threshold 0.5 is 0.6560632836825718\n",
      "Best F1 score was at threshold 0.28, 0.6842327744117233\n",
      "56370/56370 [==============================] - 4s 62us/step\n"
     ]
    }
   ],
   "source": [
    "print (\"Attention Sandwich model\")\n",
    "(best_thresh, best_f1, pred_glove_val_y) = calc_f1_scores (model, val_X, val_y)\n",
    "\n",
    "s0_test = np.zeros((test_X.shape[0], n_q))\n",
    "c0_test = np.zeros((test_X.shape[0], n_q))\n",
    "pred_test_y = model.predict([test_X, s0_test, c0_test], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Good results obtained with the following hyperparameters\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            Tp:\n",
    "        </td>\n",
    "        <td> 70 (maxlen) </td>\n",
    "        <td> 70 (maxlen) </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            Tq:\n",
    "        </td>\n",
    "        <td> 5 </td>\n",
    "        <td> 6 </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            n_p:\n",
    "        </td>\n",
    "        <td> 256 </td>\n",
    "        <td> 256 </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            n_q:\n",
    "        </td>\n",
    "        <td> 128 </td>\n",
    "        <td> 128 </td>\n",
    "            <td> 160 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            Optimizer \n",
    "        </td>\n",
    "        <td> RMSprop </td>\n",
    "        <td> RMSprop </td>\n",
    "    </tr>\n",
    "                <tr>\n",
    "        <td>\n",
    "            Learning Rate \n",
    "        </td>\n",
    "        <td> 1e-3 </td>\n",
    "        <td> 1e-3 </td>\n",
    "    </tr>\n",
    "            <tr>\n",
    "        <td> Batch Size </td>\n",
    "        <td> 512 </td>\n",
    "        <td> 512 </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td>\n",
    "            Epochs \n",
    "        </td>\n",
    "        <td>3</td>\n",
    "        <td>3</td>\n",
    "    </tr>\n",
    "           <tr>\n",
    "        <td>\n",
    "            F1 Score \n",
    "        </td>\n",
    "        <td> 0.6859 </td>\n",
    "        <td> 0.6862 </td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_y = (pred_test_y > best_thresh).astype(int)\n",
    "out_df = pd.DataFrame({\"qid\":test_df[\"qid\"].values})\n",
    "out_df['prediction'] = pred_test_y\n",
    "out_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
