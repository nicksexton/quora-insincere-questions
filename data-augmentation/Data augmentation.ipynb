{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "\n",
    "we're going to experiment with augmenting the data. We'll do this by adding noise to the embedding vectors as they go into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D, Concatenate, Flatten\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1306122, 3)\n",
      "Test shape :  (56370, 2)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")\n",
    "print(\"Train shape : \",train_df.shape)\n",
    "print(\"Test shape : \",test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "_uuid": "ba5a1b8109dee2c9fbc628d5da4a7c3447d42fb8"
   },
   "outputs": [],
   "source": [
    "## split to train and val\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.08, random_state=2018)\n",
    "\n",
    "## some config values \n",
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 95000 # 95000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 70 # max number of words in a question to use\n",
    "\n",
    "## fill up the missing values\n",
    "train_X = train_df[\"question_text\"].fillna(\"_##_\").values\n",
    "val_X = val_df[\"question_text\"].fillna(\"_##_\").values\n",
    "test_X = test_df[\"question_text\"].fillna(\"_##_\").values\n",
    "\n",
    "## Tokenize the sentences\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(train_X))\n",
    "train_X = tokenizer.texts_to_sequences(train_X)\n",
    "val_X = tokenizer.texts_to_sequences(val_X)\n",
    "test_X = tokenizer.texts_to_sequences(test_X)\n",
    "\n",
    "## Pad the sentences \n",
    "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
    "val_X = pad_sequences(val_X, maxlen=maxlen)\n",
    "test_X = pad_sequences(test_X, maxlen=maxlen)\n",
    "\n",
    "## Get the target values\n",
    "train_y = train_df['target'].values\n",
    "val_y = val_df['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "99fb1723254a245f202f1b14f1d23b6504a67483"
   },
   "source": [
    "**Attention Layer:** https://www.kaggle.com/suicaokhoailang/lstm-attention-baseline-0-652-lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "_uuid": "300d3758931b540bb6bc82958e23fcce8f70ea4f"
   },
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "_uuid": "b9d263852f653e466e24f9827548d7d1a7ee7262"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove.840B.300d\t\t\tparagram_300_sl999\r\n",
      "GoogleNews-vectors-negative300\twiki-news-300d-1M\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../input/embeddings/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Some Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7c0010e518288bc7f588776c58610949140a139a"
   },
   "source": [
    "We have four different types of embeddings.\n",
    " * GoogleNews-vectors-negative300 - https://code.google.com/archive/p/word2vec/\n",
    " * glove.840B.300d - https://nlp.stanford.edu/projects/glove/\n",
    " * paragram_300_sl999 - https://cogcomp.org/page/resource_view/106\n",
    " * wiki-news-300d-1M - https://fasttext.cc/docs/en/english-vectors.html\n",
    " \n",
    " A very good explanation for different types of embeddings are given in this [kernel](https://www.kaggle.com/sbongo/do-pretrained-embeddings-give-you-the-extra-edge). Please refer the same for more details..\n",
    "\n",
    "**Glove Embeddings:**\n",
    "\n",
    "In this section, let us use the Glove embeddings with LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "_uuid": "23f130e80159bb1701e449e2e91199dbfff1f1d4"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
    "\n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,    15, 27975,  1469, 24011], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 70, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[train_X[0:10]].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation strategy is adding an additional multiplier p training examples (ie. total training set is p\\*m examples) where additional examples are obtained by adding noise to the embedding vector. \n",
    "\n",
    "We could additionally try translations on all the embedding vectors (based on word analogy rationale).\n",
    "\n",
    "First, let's get a matrix of training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1105501, 70)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's write a generator function that manually converts train data to embedding matrix\n",
    "\n",
    "def x_generator(x_data, y_data, embedding_matrix, max_features, batch_size = 512):\n",
    "    n_batches = int(x_data.shape[0] / batch_size)\n",
    "    \n",
    "    # set lower index for this batch\n",
    "    batch_lower = 0\n",
    "    \n",
    "    while True:\n",
    "                \n",
    "        batch_upper = batch_lower + batch_size\n",
    "        #handle the final batch\n",
    "        if batch_upper > x_data.shape[0]:\n",
    "            batch_upper = x_data.shape[0]\n",
    "            \n",
    "        x_batch = x_data[batch_lower:batch_upper,:]\n",
    "        y_batch = y_data[batch_lower:batch_upper]\n",
    "        \n",
    "        x_batch_embeddings = embedding_matrix[x_batch]\n",
    "        \n",
    "        \n",
    "        batch_lower += batch_size\n",
    "        \n",
    "        #handle the final batch\n",
    "        if batch_lower > x_data.shape[0]:\n",
    "            batch_lower = 0\n",
    "        \n",
    "        yield x_batch_embeddings, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modifying the generator to augment the data by duplicating the batch and adding noise\n",
    "def x_generator_augment(x_data, y_data, embedding_matrix, emb_std, max_features, batch_size=512, #\n",
    "                    augment_factor=4, noise_scale=0.1):\n",
    "    \"\"\"\n",
    "    emb_std is the standard deviation of the embedding matrix\n",
    "    max_features is the number of tokenized words\n",
    "    batch_size is the size of the training batch to augment\n",
    "    augment_factor is the multiplier for the size of the augmented batch\n",
    "    noise_scale is how many standard deviations to scale the noise by\n",
    "    \"\"\"\n",
    "    n_batches = int(x_data.shape[0] / batch_size)\n",
    "    \n",
    "    \n",
    "    # set lower index for this batch\n",
    "    batch_lower = 0\n",
    "    \n",
    "    \n",
    "    # every time we loop round, shuffle the training set\n",
    "    np.random.seed(batch_lower)\n",
    "    \n",
    "    # not using shuffled for now\n",
    "    rnd_idx = np.random.permutation(len(x_data))\n",
    "    x_shuffled = x_data[rnd_idx]\n",
    "    y_shuffled = y_data[rnd_idx]\n",
    "    \n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        batch_upper = batch_lower + batch_size\n",
    "        #handle the final batch\n",
    "        if batch_upper > x_data.shape[0]:\n",
    "            batch_upper = x_data.shape[0]\n",
    "            \n",
    "        x_batch = x_data[batch_lower:batch_upper,:]\n",
    "        y_batch = y_data[batch_lower:batch_upper]\n",
    "        batch_embeddings = embedding_matrix[x_batch]\n",
    "        \n",
    "        # create an empty list for the augmented batches\n",
    "        augmented_batches = [batch_embeddings]\n",
    "        y_batches = [y_batch]\n",
    "        \n",
    "        for p in range (augment_factor):\n",
    "            noise = np.random.normal(0, emb_std * noise_scale, (batch_embeddings.shape))\n",
    "            aug = np.add (noise, batch_embeddings)\n",
    "            augmented_batches.append(aug)\n",
    "            y_batches.append(y_batch)\n",
    "        \n",
    "        x_augmented = np.vstack((augmented_batches))\n",
    "        y_augmented = np.hstack((y_batches))\n",
    "        \n",
    "        # now reset the counters for the next iteration\n",
    "        batch_lower += batch_size\n",
    "        \n",
    "        #reset the generator and reshuffle the training set\n",
    "        if batch_lower > x_data.shape[0]:\n",
    "            batch_lower = 0\n",
    "            rnd_idx = np.random.permutation(len(x_data))\n",
    "            x_shuffled = x_data[rnd_idx]\n",
    "            y_shuffled = y_data[rnd_idx]\n",
    "        \n",
    "        yield x_augmented, y_augmented\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 70, 300) (512,)\n"
     ]
    }
   ],
   "source": [
    "#let's test out the generator by looking at the shapes of the data it outputs\n",
    "\n",
    "x, y = train_generator.__next__()\n",
    "print (x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "23f130e80159bb1701e449e2e91199dbfff1f1d4"
   },
   "outputs": [],
   "source": [
    "# ORIGINAL MODEL CODE        \n",
    "#inp = Input(shape=(maxlen,))\n",
    "#x = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "#x = Bidirectional(CuDNNLSTM(128, return_sequences=True))(x)\n",
    "#x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n",
    "#x = Attention(maxlen)(x)\n",
    "#x = Dense(64, activation=\"relu\")(x)\n",
    "#x = Dense(1, activation=\"sigmoid\")(x)\n",
    "#model = Model(inputs=inp, outputs=x)\n",
    "#model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-3), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a modification of the LSTM attention model, where we also feed in the internal states of the LSTMs into the fully connected layers. Note that each LSTM has two internal states (c and s) for each of the forward and backward directions. This ends up with quite a lot of units in the Concatenate layer so there's another fully connected layer to reduce the number of units toward the softmax classifier more gradually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_attention_model(embed_matrix):\n",
    "    inp = Input(shape=(maxlen,embed_size))\n",
    "#    x = Embedding(max_features, embed_size, weights=[embed_matrix], trainable=False)(inp)\n",
    "    # get internal states of LSTM, both forward and back\n",
    "    [x, s_1f, s_1b, c_1f, c_1b] = Bidirectional(CuDNNLSTM(128, return_sequences=True, return_state=True))(inp)\n",
    "    [x, s_2f, s_2b, c_2f, c_2b] = Bidirectional(CuDNNLSTM(64, return_sequences=True, return_state=True))(x)\n",
    "    x = Attention(maxlen)(x)\n",
    "    \n",
    "    # fully connected part of model, takes internal states of both LSTMs as well as the output of LSTM2\n",
    "    x = Concatenate()([x, s_1f, s_1b, c_1f, c_1b, s_2f, s_2b, c_2f, c_2b])\n",
    "    x = Dense(256, activation=\"relu\")(x)\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=1e-3), metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And code to evaluate the model (F1 scores at various thresholds) on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def calc_f1_scores(model, dev_x, dev_y):\n",
    "\n",
    "    dev_x_embeddings = embedding_matrix[dev_x]\n",
    "\n",
    "    pred_glove_dev_Y = model.predict([dev_x_embeddings], batch_size=1024, verbose=1)\n",
    "\n",
    "    best_thresh = -1 # init value\n",
    "    best_f1 = 0\n",
    "\n",
    "    for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "\n",
    "        thresh = np.round(thresh, 2)\n",
    "    \n",
    "        f1 = metrics.f1_score(dev_y, (pred_glove_dev_Y>thresh).astype(int))\n",
    "        print(\"F1 score at threshold {0} is {1}\".format(thresh, f1))\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_thresh = thresh\n",
    "\n",
    "        \n",
    "    print(\"Best F1 score was at threshold {0}, {1}\".format(best_thresh, best_f1))\n",
    "    return (best_thresh, best_f1, pred_glove_dev_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the models. First, the untuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 70, 300)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) [(None, 70, 256), (N 440320      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) [(None, 70, 128), (N 164864      bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         (None, 128)          198         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 896)          0           attention_1[0][0]                \n",
      "                                                                 bidirectional_1[0][1]            \n",
      "                                                                 bidirectional_1[0][2]            \n",
      "                                                                 bidirectional_1[0][3]            \n",
      "                                                                 bidirectional_1[0][4]            \n",
      "                                                                 bidirectional_2[0][1]            \n",
      "                                                                 bidirectional_2[0][2]            \n",
      "                                                                 bidirectional_2[0][3]            \n",
      "                                                                 bidirectional_2[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          229632      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           16448       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            65          dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 851,527\n",
      "Trainable params: 851,527\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_attention_model(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num train batches: 1080\n",
      "num val batches: 94\n"
     ]
    }
   ],
   "source": [
    "# Configure the generator\n",
    "batch_size=1024\n",
    "num_train_batches = math.ceil(train_X.shape[0] / batch_size)\n",
    "num_val_batches = math.ceil(val_X.shape[0] / batch_size)\n",
    "print (\"num train batches:\", num_train_batches)\n",
    "print (\"num val batches:\", num_val_batches)\n",
    "\n",
    "train_generator = x_generator_augment(train_X, train_y, embedding_matrix, emb_std, max_features, batch_size=batch_size, \n",
    "                    augment_factor=0, noise_scale=0.05)\n",
    "\n",
    "val_generator = x_generator(val_X, val_y, embedding_matrix, max_features, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the data augmentation\n",
    "\n",
    "Model built, data augmentation algorithm built into the generator, let's test out whether we can get an improvement in prediction accuracy/F1 score by comparing the model trained on the original dataset (trained until it starts to overfit) with the same model trained on the augmented data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "a560ab0dbab9cf6fdbdae6721ec030e300f19d78",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1080/1080 [==============================] - 132s 122ms/step - loss: 0.1142 - acc: 0.9551 - val_loss: 0.1070 - val_acc: 0.9577\n",
      "Epoch 2/3\n",
      "1080/1080 [==============================] - 133s 123ms/step - loss: 0.1037 - acc: 0.9590 - val_loss: 0.1025 - val_acc: 0.9591\n",
      "Epoch 3/3\n",
      "1080/1080 [==============================] - 133s 124ms/step - loss: 0.0980 - acc: 0.9610 - val_loss: 0.1032 - val_acc: 0.9593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f71285a48d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, steps_per_epoch=num_train_batches, epochs=3, \n",
    "                    validation_data=val_generator, validation_steps=num_val_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model\n",
      "96131/96131 [==============================] - 9s 96us/step\n",
      "F1 score at threshold 0.1 is 0.5705485635388455\n",
      "F1 score at threshold 0.11 is 0.5796503420566836\n",
      "F1 score at threshold 0.12 is 0.5882287679591724\n",
      "F1 score at threshold 0.13 is 0.5963323522753\n",
      "F1 score at threshold 0.14 is 0.6032881453706375\n",
      "F1 score at threshold 0.15 is 0.6103468547912992\n",
      "F1 score at threshold 0.16 is 0.6155685758699032\n",
      "F1 score at threshold 0.17 is 0.6214654910307085\n",
      "F1 score at threshold 0.18 is 0.6262526289743907\n",
      "F1 score at threshold 0.19 is 0.6311094358587762\n",
      "F1 score at threshold 0.2 is 0.6364448984803984\n",
      "F1 score at threshold 0.21 is 0.6400465959099145\n",
      "F1 score at threshold 0.22 is 0.6439697666776207\n",
      "F1 score at threshold 0.23 is 0.6474034620505993\n",
      "F1 score at threshold 0.24 is 0.6503812672919901\n",
      "F1 score at threshold 0.25 is 0.6523135807531953\n",
      "F1 score at threshold 0.26 is 0.6541176470588235\n",
      "F1 score at threshold 0.27 is 0.6565847511027095\n",
      "F1 score at threshold 0.28 is 0.6584951112370696\n",
      "F1 score at threshold 0.29 is 0.6604017216642755\n",
      "F1 score at threshold 0.3 is 0.6614413237535379\n",
      "F1 score at threshold 0.31 is 0.6630906018076274\n",
      "F1 score at threshold 0.32 is 0.665377751338489\n",
      "F1 score at threshold 0.33 is 0.6662657847263981\n",
      "F1 score at threshold 0.34 is 0.6661596958174905\n",
      "F1 score at threshold 0.35 is 0.6671787387664183\n",
      "F1 score at threshold 0.36 is 0.6675984160260889\n",
      "F1 score at threshold 0.37 is 0.6672419203012236\n",
      "F1 score at threshold 0.38 is 0.6680932001902045\n",
      "F1 score at threshold 0.39 is 0.6667199872030712\n",
      "F1 score at threshold 0.4 is 0.6661291622994437\n",
      "F1 score at threshold 0.41 is 0.6652552723719567\n",
      "F1 score at threshold 0.42 is 0.6655149720302731\n",
      "F1 score at threshold 0.43 is 0.6655049373495975\n",
      "F1 score at threshold 0.44 is 0.6636531056420559\n",
      "F1 score at threshold 0.45 is 0.6616020933569681\n",
      "F1 score at threshold 0.46 is 0.6600255427841636\n",
      "F1 score at threshold 0.47 is 0.6584800343495062\n",
      "F1 score at threshold 0.48 is 0.6566155445801923\n",
      "F1 score at threshold 0.49 is 0.6557032890132961\n",
      "F1 score at threshold 0.5 is 0.6513437057991514\n",
      "Best F1 score was at threshold 0.38, 0.6680932001902045\n",
      "56370/56370 [==============================] - 5s 93us/step\n"
     ]
    }
   ],
   "source": [
    "print (\"Original model\")\n",
    "(best_thresh, best_f1, pred_glove_val_y) = calc_f1_scores (model, val_X, val_y)\n",
    "pred_glove_test_y = model.predict([embedding_matrix[test_X]], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmented model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 70, 300)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional [(None, 70, 256), (N 440320      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_12 (Bidirectional [(None, 70, 128), (N 164864      bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_6 (Attention)         (None, 128)          198         bidirectional_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 896)          0           attention_6[0][0]                \n",
      "                                                                 bidirectional_11[0][1]           \n",
      "                                                                 bidirectional_11[0][2]           \n",
      "                                                                 bidirectional_11[0][3]           \n",
      "                                                                 bidirectional_11[0][4]           \n",
      "                                                                 bidirectional_12[0][1]           \n",
      "                                                                 bidirectional_12[0][2]           \n",
      "                                                                 bidirectional_12[0][3]           \n",
      "                                                                 bidirectional_12[0][4]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 256)          229632      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 64)           16448       dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1)            65          dense_17[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 851,527\n",
      "Trainable params: 851,527\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# rebuild the model\n",
    "model = build_attention_model(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num train batches: 8637\n",
      "num val batches: 752\n"
     ]
    }
   ],
   "source": [
    "batch_size=128\n",
    "num_train_batches = math.ceil(train_X.shape[0] / batch_size)\n",
    "num_val_batches = math.ceil(val_X.shape[0] / batch_size)\n",
    "print (\"num train batches:\", num_train_batches)\n",
    "print (\"num val batches:\", num_val_batches)\n",
    "\n",
    "train_generator = x_generator_augment(train_X, train_y, embedding_matrix, emb_std, max_features, batch_size=batch_size, \n",
    "                    augment_factor=1, noise_scale=0.15)\n",
    "\n",
    "val_generator = x_generator(val_X, val_y, embedding_matrix, max_features, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "8637/8637 [==============================] - 738s 85ms/step - loss: 0.1192 - acc: 0.9542 - val_loss: 0.1108 - val_acc: 0.9574\n",
      "Epoch 2/3\n",
      "8637/8637 [==============================] - 738s 85ms/step - loss: 0.1107 - acc: 0.9582 - val_loss: 0.1138 - val_acc: 0.9590\n",
      "Epoch 3/3\n",
      "8637/8637 [==============================] - 737s 85ms/step - loss: 0.1064 - acc: 0.9600 - val_loss: 0.1174 - val_acc: 0.9590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f71383315c0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, steps_per_epoch=num_train_batches, epochs=3, \n",
    "                    validation_data=val_generator, validation_steps=num_val_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented model\n",
      "96131/96131 [==============================] - 9s 94us/step\n",
      "F1 score at threshold 0.1 is 0.5705485635388455\n",
      "F1 score at threshold 0.11 is 0.5796503420566836\n",
      "F1 score at threshold 0.12 is 0.5882287679591724\n",
      "F1 score at threshold 0.13 is 0.5963323522753\n",
      "F1 score at threshold 0.14 is 0.6032881453706375\n",
      "F1 score at threshold 0.15 is 0.6103468547912992\n",
      "F1 score at threshold 0.16 is 0.6155685758699032\n",
      "F1 score at threshold 0.17 is 0.6214654910307085\n",
      "F1 score at threshold 0.18 is 0.6262526289743907\n",
      "F1 score at threshold 0.19 is 0.6311094358587762\n",
      "F1 score at threshold 0.2 is 0.6364448984803984\n",
      "F1 score at threshold 0.21 is 0.6400465959099145\n",
      "F1 score at threshold 0.22 is 0.6439697666776207\n",
      "F1 score at threshold 0.23 is 0.6474034620505993\n",
      "F1 score at threshold 0.24 is 0.6503812672919901\n",
      "F1 score at threshold 0.25 is 0.6523135807531953\n",
      "F1 score at threshold 0.26 is 0.6541176470588235\n",
      "F1 score at threshold 0.27 is 0.6565847511027095\n",
      "F1 score at threshold 0.28 is 0.6584951112370696\n",
      "F1 score at threshold 0.29 is 0.6604017216642755\n",
      "F1 score at threshold 0.3 is 0.6614413237535379\n",
      "F1 score at threshold 0.31 is 0.6630906018076274\n",
      "F1 score at threshold 0.32 is 0.665377751338489\n",
      "F1 score at threshold 0.33 is 0.6662657847263981\n",
      "F1 score at threshold 0.34 is 0.6661596958174905\n",
      "F1 score at threshold 0.35 is 0.6671787387664183\n",
      "F1 score at threshold 0.36 is 0.6675984160260889\n",
      "F1 score at threshold 0.37 is 0.6672419203012236\n",
      "F1 score at threshold 0.38 is 0.6680932001902045\n",
      "F1 score at threshold 0.39 is 0.6667199872030712\n",
      "F1 score at threshold 0.4 is 0.6661291622994437\n",
      "F1 score at threshold 0.41 is 0.6652552723719567\n",
      "F1 score at threshold 0.42 is 0.6655149720302731\n",
      "F1 score at threshold 0.43 is 0.6655049373495975\n",
      "F1 score at threshold 0.44 is 0.6636531056420559\n",
      "F1 score at threshold 0.45 is 0.6616020933569681\n",
      "F1 score at threshold 0.46 is 0.6600255427841636\n",
      "F1 score at threshold 0.47 is 0.6584800343495062\n",
      "F1 score at threshold 0.48 is 0.6566155445801923\n",
      "F1 score at threshold 0.49 is 0.6557032890132961\n",
      "F1 score at threshold 0.5 is 0.6513437057991514\n",
      "Best F1 score was at threshold 0.38, 0.6680932001902045\n",
      "56370/56370 [==============================] - 5s 93us/step\n"
     ]
    }
   ],
   "source": [
    "print (\"Augmented model\")\n",
    "(best_thresh, best_f1, pred_glove_val_y) = calc_f1_scores (model, val_X, val_y)\n",
    "pred_augmented_test_y = model.predict([embedding_matrix[test_X]], batch_size=1024, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
